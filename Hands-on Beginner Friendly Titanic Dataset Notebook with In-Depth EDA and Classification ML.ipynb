{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"competition","sourceId":3136,"databundleVersionId":26502}],"dockerImageVersionId":31286,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ishwor2048/beginner-friendly-titanic-eda-and-machine-learning?scriptVersionId=300531594\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"<h1><b>Titanic Dataset Hands-on Data Overview, EDA and Classification Machine Learning</b></h1>","metadata":{}},{"cell_type":"markdown","source":"Hello Everyone, <br>\nIn this notebook, I have included most possible data overview, exploratory data analysis, data visualization, data pre-processing, machine learning life-cycle, and saving model locally. I hope you are going to learn a ton from this notebook. This notebook will be constantly updated, and this is just beginning, and I want learners to take the best advantage out of this notebook and analysis. so please do not forget to check the most updated one next time as I am updating this notebook frequently with additional analysis, visualization, comments and models based on the viewers comments!<br><br>\n**If you want to  learn something specific, please feel free to COMMENT, I will provide in-depth deep dive into it. Also, if you liked my work on this, please hit UPVOTE, so that it will reach more learners.** <br><br>\nFor better practice, I will be using training data, and split to validation set to provide full practice of data preprocessing, but in the titanic specific data, we do not need to perform train-test split which I have used in order to do the submission to Kaggle.\n<br><br>\nPlease also do not forget to check my YouTube channel as I am constructing hands-on tutorial from this notebook, and this will be updated there:\nhttps://www.youtube.com/@DataSpeaks4u","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1><b>Basic Imports","metadata":{}},{"cell_type":"markdown","source":"Let's begin our project with importing necessary libraries and modules. Working with python is really powerful for Data Science projects with very powerful libraries, modules and frameworks that will help you with not having to write code from scratch to accomplish specific tasks, including data visualization, exploratory data analysis, machine learning and deployments. Please go through the imports below, and let me know in comments if you got any questions.","metadata":{}},{"cell_type":"code","source":"# =============================\n# Core data and computation libs\n# =============================\nimport numpy as np  # NumPy: fundamental package for fast numerical computing (arrays, random numbers, linear algebra)\nimport pandas as pd  # pandas: tabular data structures (DataFrame/Series) for data loading, cleaning, joins, and EDA\n\n# =============================\n# Visualization libraries\n# =============================\nimport matplotlib.pyplot as plt  # Matplotlib (stateful pyplot API): low-level plotting, figure/axes control\nimport seaborn as sns  # Seaborn: higher-level statistical plots with nicer defaults; built on top of Matplotlib\n\n# ===============================================================\n# scikit-learn utilities: data split, preprocessing, and pipelines\n# ===============================================================\n# Train/validation/test splitting (train_test_split),\n# StratifiedKFold for balanced class distributions across folds during CV,\n# and GridSearchCV for exhaustive hyperparameter search with cross-validation.\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n\n# ColumnTransformer lets you apply different preprocessing to different column subsets\n# (e.g., numeric vs categorical pipelines).\nfrom sklearn.compose import ColumnTransformer\n\n# Pipeline chains preprocessing steps and estimator into a single object\n# to ensure no data leakage and consistent application during fit/predict.\nfrom sklearn.pipeline import Pipeline\n\n# Common preprocessing transformers:\n# - OneHotEncoder: convert categorical features to one-hot/dummy variables.\n# - StandardScaler: standardize numeric features (mean=0, std=1), critical for distance-based or linear-margin models.\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\n\n# SimpleImputer: handle missing values (e.g., strategy='mean' for numeric, 'most_frequent' for categorical).\nfrom sklearn.impute import SimpleImputer\n\n# =======================\n# scikit-learn classifiers\n# =======================\n# Decision Tree: non-linear, interpretable, prone to overfitting if not regularized (max_depth, min_samples_split, etc.).\nfrom sklearn.tree import DecisionTreeClassifier\n\n# Random Forest: ensemble of trees; reduces variance; good baseline for tabular data; handles mixed feature types well.\nfrom sklearn.ensemble import RandomForestClassifier\n\n# K-Nearest Neighbors: instance-based learner; sensitive to scale (hence StandardScaler); choose k via CV.\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# Support Vector Classifier: effective in high-dimensional spaces; sensitive to feature scaling; kernels (linear/RBF/poly).\nfrom sklearn.svm import SVC\n\n# ==============================\n# Metrics and diagnostic utilities\n# ==============================\nfrom sklearn.metrics import (\n    accuracy_score,              # Overall fraction of correct predictions (may be misleading with class imbalance).\n    precision_score,             # Of predicted positives, how many are correct (TP / (TP + FP)).\n    recall_score,                # Of actual positives, how many were found (TP / (TP + FN)).\n    f1_score,                    # Harmonic mean of precision and recall; balances both for imbalanced classes.\n    roc_auc_score,               # Area under ROC curve; threshold-independent measure (binary & probability-based).\n    classification_report,       # Nicely formatted precision/recall/F1/support per class.\n    confusion_matrix,            # 2x2 (binary) or CxC (multi-class) matrix of predicted vs actual counts.\n    RocCurveDisplay,             # Helper to plot ROC curve (TPR vs FPR across thresholds).\n    PrecisionRecallDisplay       # Helper to plot Precision-Recall curve (especially informative on imbalanced data).\n)\n\n# =======================\n# Persistence / I/O helper\n# =======================\nimport joblib  # For saving/loading trained models, pipelines, and preprocessors efficiently (pickle-compatible).\n\n# =======================\n# Reproducibility controls\n# =======================\nRANDOM_STATE = 42  # Fixed seed value used wherever estimators/splitters accept random_state for reproducible results.\nnp.random.seed(RANDOM_STATE)  # Also seed NumPy's RNG when generating synthetic data or random operations outside sklearn.\n\n# =======================\n# Sanity message\n# =======================\n# Basic confirmation that the imports executed without error.\n# Useful in notebooks or scripts to ensure environment dependencies are satisfied before proceeding.\nprint(\"Imports loaded!ðŸ¤–\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T17:11:56.838213Z","iopub.execute_input":"2026-02-27T17:11:56.838891Z","iopub.status.idle":"2026-02-27T17:11:58.977067Z","shell.execute_reply.started":"2026-02-27T17:11:56.838851Z","shell.execute_reply":"2026-02-27T17:11:58.976246Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3><b>Load the data (Kaggle Built-in Titanic Dataset)","metadata":{}},{"cell_type":"markdown","source":"Before loading here, it is important that we load the data into the \"INPUT\" section to the right panel","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/competitions/titanic/train.csv\"\ntest_path = \"/kaggle/input/competitions/titanic/test.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:26.905251Z","iopub.execute_input":"2026-02-27T03:30:26.905746Z","iopub.status.idle":"2026-02-27T03:30:26.911701Z","shell.execute_reply.started":"2026-02-27T03:30:26.905716Z","shell.execute_reply":"2026-02-27T03:30:26.910455Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Loading the training dataset from the path defined above, and naming it to \"df\"","metadata":{}},{"cell_type":"code","source":"# define the df\ndf = pd.read_csv(train_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:26.916548Z","iopub.execute_input":"2026-02-27T03:30:26.916931Z","iopub.status.idle":"2026-02-27T03:30:26.949585Z","shell.execute_reply.started":"2026-02-27T03:30:26.916894Z","shell.execute_reply":"2026-02-27T03:30:26.948443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"There are {df.shape[0]} rows and {df.shape[1]} columns in the dataset.\") # check number of rows and columns in the dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:26.951738Z","iopub.execute_input":"2026-02-27T03:30:26.952164Z","iopub.status.idle":"2026-02-27T03:30:26.957859Z","shell.execute_reply.started":"2026-02-27T03:30:26.952138Z","shell.execute_reply":"2026-02-27T03:30:26.956625Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# getting the top 5 rows of the data\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:26.959259Z","iopub.execute_input":"2026-02-27T03:30:26.959604Z","iopub.status.idle":"2026-02-27T03:30:27.003974Z","shell.execute_reply.started":"2026-02-27T03:30:26.959566Z","shell.execute_reply":"2026-02-27T03:30:27.003001Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Getting top 3 rows of the dataset\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.005296Z","iopub.execute_input":"2026-02-27T03:30:27.005728Z","iopub.status.idle":"2026-02-27T03:30:27.019294Z","shell.execute_reply.started":"2026-02-27T03:30:27.00568Z","shell.execute_reply":"2026-02-27T03:30:27.018278Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Getting last 5 rows of the dataset\ndf.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.020647Z","iopub.execute_input":"2026-02-27T03:30:27.021109Z","iopub.status.idle":"2026-02-27T03:30:27.042314Z","shell.execute_reply.started":"2026-02-27T03:30:27.021064Z","shell.execute_reply":"2026-02-27T03:30:27.041381Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Getting last 7 rows of the training dataset\ndf.tail(7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.04402Z","iopub.execute_input":"2026-02-27T03:30:27.044374Z","iopub.status.idle":"2026-02-27T03:30:27.066529Z","shell.execute_reply.started":"2026-02-27T03:30:27.044339Z","shell.execute_reply":"2026-02-27T03:30:27.065524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Getting sample 5 rows of the dataset. This function will pick the random 5 rows. Notice the index positions\ndf.sample(5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.068031Z","iopub.execute_input":"2026-02-27T03:30:27.06839Z","iopub.status.idle":"2026-02-27T03:30:27.096952Z","shell.execute_reply.started":"2026-02-27T03:30:27.068342Z","shell.execute_reply":"2026-02-27T03:30:27.095843Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking information about the data in overall\ndf.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.09809Z","iopub.execute_input":"2026-02-27T03:30:27.098551Z","iopub.status.idle":"2026-02-27T03:30:27.125607Z","shell.execute_reply.started":"2026-02-27T03:30:27.09849Z","shell.execute_reply":"2026-02-27T03:30:27.124439Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Getting quick statistical summary of the numerical columns\ndf.describe().T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.127226Z","iopub.execute_input":"2026-02-27T03:30:27.127668Z","iopub.status.idle":"2026-02-27T03:30:27.165904Z","shell.execute_reply.started":"2026-02-27T03:30:27.127643Z","shell.execute_reply":"2026-02-27T03:30:27.164858Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Getting statistical summary of categorical columns\ndf.describe(include=\"object\").T","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.167057Z","iopub.execute_input":"2026-02-27T03:30:27.16743Z","iopub.status.idle":"2026-02-27T03:30:27.186149Z","shell.execute_reply.started":"2026-02-27T03:30:27.167396Z","shell.execute_reply":"2026-02-27T03:30:27.185165Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking list of columns\ndf.columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.190467Z","iopub.execute_input":"2026-02-27T03:30:27.190882Z","iopub.status.idle":"2026-02-27T03:30:27.196968Z","shell.execute_reply.started":"2026-02-27T03:30:27.190856Z","shell.execute_reply":"2026-02-27T03:30:27.196018Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3><b>Quick EDA for Sanity Check","metadata":{}},{"cell_type":"code","source":"# Checking balance of the labels\nround(df[\"Survived\"].value_counts(normalize=True) * 100, 2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.198041Z","iopub.execute_input":"2026-02-27T03:30:27.198476Z","iopub.status.idle":"2026-02-27T03:30:27.219999Z","shell.execute_reply.started":"2026-02-27T03:30:27.198384Z","shell.execute_reply":"2026-02-27T03:30:27.219077Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking missing values\ndf.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.221305Z","iopub.execute_input":"2026-02-27T03:30:27.221639Z","iopub.status.idle":"2026-02-27T03:30:27.238904Z","shell.execute_reply.started":"2026-02-27T03:30:27.221595Z","shell.execute_reply":"2026-02-27T03:30:27.237966Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Checking top missing values\ndf.isna().mean().sort_values(ascending=False).head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.240065Z","iopub.execute_input":"2026-02-27T03:30:27.240546Z","iopub.status.idle":"2026-02-27T03:30:27.259882Z","shell.execute_reply.started":"2026-02-27T03:30:27.240509Z","shell.execute_reply":"2026-02-27T03:30:27.258884Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Quick correlation check for numerical columns\nnum_cols = df.select_dtypes(include=[np.number]).columns\n\ncorr = round(df[num_cols].corr(numeric_only=True), 4)\ndisplay(corr)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.261701Z","iopub.execute_input":"2026-02-27T03:30:27.262094Z","iopub.status.idle":"2026-02-27T03:30:27.281195Z","shell.execute_reply.started":"2026-02-27T03:30:27.26203Z","shell.execute_reply":"2026-02-27T03:30:27.28025Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3><b>Data Visualization for additional data exploration","metadata":{}},{"cell_type":"code","source":"# Visualizing the survival vs non-survival\nax = sns.countplot(x='Survived', data=df, hue='Survived')\nplt.title(\"Count of Survival (Target)\")\n\nfor container in ax.containers:\n    ax.bar_label(container)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.282434Z","iopub.execute_input":"2026-02-27T03:30:27.282747Z","iopub.status.idle":"2026-02-27T03:30:27.532536Z","shell.execute_reply.started":"2026-02-27T03:30:27.282722Z","shell.execute_reply":"2026-02-27T03:30:27.531481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Correlation heatmap\nplt.figure(figsize=(10, 6))\nsns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm', fmt='.2f')\nplt.title(\"Feature Correlation Heatmap\")\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.533948Z","iopub.execute_input":"2026-02-27T03:30:27.53431Z","iopub.status.idle":"2026-02-27T03:30:27.844751Z","shell.execute_reply.started":"2026-02-27T03:30:27.534273Z","shell.execute_reply":"2026-02-27T03:30:27.843671Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# categorical pivot table: Survival based on gender\nround(df[[\"Sex\", \"Survived\"]].groupby(['Sex']).mean(), 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.846148Z","iopub.execute_input":"2026-02-27T03:30:27.846513Z","iopub.status.idle":"2026-02-27T03:30:27.860361Z","shell.execute_reply.started":"2026-02-27T03:30:27.846477Z","shell.execute_reply":"2026-02-27T03:30:27.859481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# categorical pivot table: Survival rate by Passenger class\nround(df[[\"Pclass\", \"Survived\"]].groupby(['Pclass']).mean(), 3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.861603Z","iopub.execute_input":"2026-02-27T03:30:27.862024Z","iopub.status.idle":"2026-02-27T03:30:27.883432Z","shell.execute_reply.started":"2026-02-27T03:30:27.86199Z","shell.execute_reply":"2026-02-27T03:30:27.882666Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Age distribution by survival (KDE PLOT)\nsns.kdeplot(data=df, x='Age', hue='Survived', fill=True, palette='viridis')\nplt.title(\"Age density Distribution by Survival\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:27.884651Z","iopub.execute_input":"2026-02-27T03:30:27.885369Z","iopub.status.idle":"2026-02-27T03:30:28.186688Z","shell.execute_reply.started":"2026-02-27T03:30:27.885332Z","shell.execute_reply":"2026-02-27T03:30:28.18585Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# fair vs age vs survival scatter plot\nsns.scatterplot(data=df, x='Age', y='Fare', hue='Survived', alpha=0.7)\nplt.title(\"Relationship between Age, Fare and Survival\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:28.188272Z","iopub.execute_input":"2026-02-27T03:30:28.188734Z","iopub.status.idle":"2026-02-27T03:30:28.464727Z","shell.execute_reply.started":"2026-02-27T03:30:28.188706Z","shell.execute_reply":"2026-02-27T03:30:28.463674Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# survival rate by family size\ndf[\"FamilySize\"] = df[\"SibSp\"] + df[\"Parch\"] + 1\nsns.barplot(data=df, x = 'FamilySize', y = 'Survived')\nplt.title(\"Survival Rate by Family Size\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:28.466107Z","iopub.execute_input":"2026-02-27T03:30:28.466683Z","iopub.status.idle":"2026-02-27T03:30:28.825409Z","shell.execute_reply.started":"2026-02-27T03:30:28.466649Z","shell.execute_reply":"2026-02-27T03:30:28.82452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Passenger class and sex interaction (catplot)\nsns.catplot(x='Pclass', y='Survived', hue='Sex', data=df, kind='point')\nplt.title(\"Survival Probability: Sex vs Pclass\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:28.826653Z","iopub.execute_input":"2026-02-27T03:30:28.827057Z","iopub.status.idle":"2026-02-27T03:30:29.22909Z","shell.execute_reply.started":"2026-02-27T03:30:28.827023Z","shell.execute_reply":"2026-02-27T03:30:29.22822Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Embarked port vs Survival vs. Pclass\nsns.pointplot(data=df, x='Embarked', y='Survived', hue='Pclass')\nplt.title(\"Surval by Port of Embarkation and Class\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:29.230165Z","iopub.execute_input":"2026-02-27T03:30:29.230515Z","iopub.status.idle":"2026-02-27T03:30:29.595834Z","shell.execute_reply.started":"2026-02-27T03:30:29.23049Z","shell.execute_reply":"2026-02-27T03:30:29.594809Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fair distribution by class\nsns.boxplot(data=df, x = 'Pclass', y = 'Fare')\nplt.ylim(0, 300) # Zoom in to ignore extreme outliers for better view\nplt.title(\"Fair Distribution across classes\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:29.597089Z","iopub.execute_input":"2026-02-27T03:30:29.597551Z","iopub.status.idle":"2026-02-27T03:30:29.770041Z","shell.execute_reply.started":"2026-02-27T03:30:29.597511Z","shell.execute_reply":"2026-02-27T03:30:29.769143Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# missing value matrix\n# Visualize the \"emptiness\" of the data \n# to see if Age or Cabin missigness is random or clustered\nsns.heatmap(df.isnull(), cbar=False, yticklabels=False, cmap='viridis')\nplt.title(\"Missing data Gap\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:29.771152Z","iopub.execute_input":"2026-02-27T03:30:29.771733Z","iopub.status.idle":"2026-02-27T03:30:29.936194Z","shell.execute_reply.started":"2026-02-27T03:30:29.771702Z","shell.execute_reply":"2026-02-27T03:30:29.935345Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"This combines a boxplot and KDE. Itâ€™s great for seeing if the age distribution of survivors in 1st class differs from 3rd class.","metadata":{}},{"cell_type":"code","source":"# Violin plot of Age by Passenger class and Survived\nsns.violinplot(data=df, x=\"Pclass\", y='Age', hue=\"Survived\", split=True)\nplt.title(\"Age/Class Distribution by Surivival\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:29.937172Z","iopub.execute_input":"2026-02-27T03:30:29.937531Z","iopub.status.idle":"2026-02-27T03:30:30.229519Z","shell.execute_reply.started":"2026-02-27T03:30:29.93749Z","shell.execute_reply":"2026-02-27T03:30:30.228513Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"You can extract titles (Mr, Mrs, Miss, Master, Dr) from the Name column. Visualizing survival by \"Title\" often reveals more than \"Sex\" alone (e.g., \"Master\" usually refers to young boys).","metadata":{}},{"cell_type":"code","source":"# Title extraction Analysis\n# We can extract the title (Mr, Mrs, Miss, Master, Dr) from the Name column.\n# Visualizing survival by \"Title\" often reveals more than \"Sex\" alone (e.g. Master usually refers to young boys)\ndf[\"Title\"] = df[\"Name\"].str.extract(r\" ([A-Za-z]+)\\.\", expand=False)\nsns.countplot(data=df, y='Title', hue=\"Survived\")\nplt.title(\"Survival Count by Title\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:30.231068Z","iopub.execute_input":"2026-02-27T03:30:30.231396Z","iopub.status.idle":"2026-02-27T03:30:30.526053Z","shell.execute_reply.started":"2026-02-27T03:30:30.231368Z","shell.execute_reply":"2026-02-27T03:30:30.525167Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"A bird's-eye view of all numerical relationships at once.","metadata":{}},{"cell_type":"code","source":"# Pairplot of numerical features\nsns.pairplot(df[num_cols].dropna(), hue=\"Survived\", diag_kind='kde')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:30.527243Z","iopub.execute_input":"2026-02-27T03:30:30.527655Z","iopub.status.idle":"2026-02-27T03:30:37.942056Z","shell.execute_reply.started":"2026-02-27T03:30:30.527616Z","shell.execute_reply":"2026-02-27T03:30:37.94106Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Standard analysis looks at individuals. However, families on the Titanic often lived or died together. You can identify groups by looking for people with the same Surname and Ticket number.","metadata":{}},{"cell_type":"code","source":"# Extract Surname\ndf['Surname'] = df['Name'].apply(lambda x: x.split(',')[0])\n\n# Create a 'FamilyGroup' identifier\ndf['FamilyGroup'] = df['Surname'] + \"_\" + df['Ticket'].str[:-1]\n\n# Find survival rates of these groups\ngroup_survival = df.groupby('FamilyGroup')['Survived'].mean()\nsns.histplot(group_survival)\nplt.title(\"Survival Consistency within Family Groups\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:37.943523Z","iopub.execute_input":"2026-02-27T03:30:37.943919Z","iopub.status.idle":"2026-02-27T03:30:38.117047Z","shell.execute_reply.started":"2026-02-27T03:30:37.943885Z","shell.execute_reply":"2026-02-27T03:30:38.116011Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"The Cabin column is 77% null, so most people drop it. However, the Letter in the cabin (A, B, C, D, E, F, G, T) represents the Deck. Decks closer to the water line had lower survival rates.","metadata":{}},{"cell_type":"code","source":"# Extract Deck from Cabin\ndf['Deck'] = df['Cabin'].str.slice(0,1)\ndf['Deck'] = df['Deck'].fillna('Unknown')\n\n# Plot Deck vs Survival, ordered by vertical height of the ship\ndeck_order = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'T', 'Unknown']\nsns.barplot(data=df, x='Deck', y='Survived', order=deck_order)\nplt.title(\"Survival Rate by Ship Deck (Vertical Location)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:38.118311Z","iopub.execute_input":"2026-02-27T03:30:38.118947Z","iopub.status.idle":"2026-02-27T03:30:38.435935Z","shell.execute_reply.started":"2026-02-27T03:30:38.118921Z","shell.execute_reply":"2026-02-27T03:30:38.434943Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Is there a \"survival ceiling\" for wealth? Instead of a scatter plot, use a cumulative distribution or a \"Binned\" bar plot to see if paying $100 vs $500 actually changed your odds.","metadata":{}},{"cell_type":"code","source":"df[\"Fare_Bin\"] = pd.qcut(df[\"Fare\"], 5)\n\nsns.barplot(data=df, x='Fare_Bin', y=\"Survived\")\nplt.xticks(rotation=45)\nplt.title(\"Survival Probability by Fare Quintiles\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:38.437208Z","iopub.execute_input":"2026-02-27T03:30:38.438269Z","iopub.status.idle":"2026-02-27T03:30:38.721503Z","shell.execute_reply.started":"2026-02-27T03:30:38.438194Z","shell.execute_reply":"2026-02-27T03:30:38.720643Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Some passengers traveled on the same ticket but weren't \"Family\" (e.g., nannies, friends, or cousins). The frequency of a ticket number tells you the total group size, which is often more accurate than SibSp + Parch.","metadata":{}},{"cell_type":"code","source":"df[\"Ticket_Freq\"] = df.groupby(\"Ticket\")[\"Ticket\"].transform('count')\nsns.pointplot(data=df, x='Ticket_Freq', y='Survived')\nplt.title(\"Survival Rate by Group Size (based on Ticket Frequency)\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:38.722943Z","iopub.execute_input":"2026-02-27T03:30:38.72338Z","iopub.status.idle":"2026-02-27T03:30:39.035716Z","shell.execute_reply.started":"2026-02-27T03:30:38.723344Z","shell.execute_reply":"2026-02-27T03:30:39.034351Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Many people just fill missing Age with the median. To see if the missingness itself is a signal, check if people with \"Missing Age\" survived at different rates than those with \"Known Age.\"","metadata":{}},{"cell_type":"code","source":"df[\"Age_Unknown\"] = df[\"Age\"].isnull().astype(int)\nsns.barplot(data=df, x=\"Age_Unknown\", y=\"Survived\", hue=\"Sex\")\nplt.title(\"Survival Rate: Known Age vs. Missing Age\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.037047Z","iopub.execute_input":"2026-02-27T03:30:39.037459Z","iopub.status.idle":"2026-02-27T03:30:39.314137Z","shell.execute_reply.started":"2026-02-27T03:30:39.037432Z","shell.execute_reply":"2026-02-27T03:30:39.313307Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To dive deeper into the relationship between categorical variables, we need to go beyond simple correlations (which only work well for numbers). We want to see if knowing one category (like Sex) gives us significant information about another (like Survival or Pclass).","metadata":{}},{"cell_type":"markdown","source":"**Chi-Square Test for Independence** is the gold standard for categorical association. It tells you if the relationship between two variables (e.g., Embarked and Survived) is statistically significant or just due to chance.","metadata":{}},{"cell_type":"code","source":"# Import necessary libraries and modules\nfrom scipy.stats import chi2_contingency\n\ndef check_categorical_association(df, col1, col2):\n    contingency_table = pd.crosstab(df[col1], df[col2])\n    chi2, p, dof, ex = chi2_contingency(contingency_table)\n    print(f\"Relationship between {col1} and {col2}:\")\n    print(f\"   - Chi-square Statistics: {chi2:.4f}\")\n    print(f\"   - P-value: {p:.4e}\")\n    return p\n\n# checking if port of Embarkatioon is related to survival\ncheck_categorical_association(df, \"Embarked\", \"Survived\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.315181Z","iopub.execute_input":"2026-02-27T03:30:39.315592Z","iopub.status.idle":"2026-02-27T03:30:39.345084Z","shell.execute_reply.started":"2026-02-27T03:30:39.315565Z","shell.execute_reply":"2026-02-27T03:30:39.344218Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"While Chi-Square tells you if there is a relationship, Cramerâ€™s V tells you how strong it is (on a scale of 0 to 1). This is essentially the \"correlation coefficient\" for categories.","metadata":{}},{"cell_type":"code","source":"def cramers_v(x, y):\n    confusion_matrix = pd.crosstab(x, y)\n    chi2 = chi2_contingency(confusion_matrix)[0]\n    n = confusion_matrix.sum().sum()\n    phi2 = chi2 / n\n    r, k = confusion_matrix.shape\n    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n    rcorr = r - ((r-1)**2)/(n-1)\n    kcorr = k - ((k-1)**2)/(n-1)\n    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n\n# Example: How strong is the link between Pclass and Survival?\nv_score = cramers_v(df['Pclass'], df['Survived'])\nprint(f\"Cramer's V for Pclass & Survived: {v_score:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.346287Z","iopub.execute_input":"2026-02-27T03:30:39.346701Z","iopub.status.idle":"2026-02-27T03:30:39.363951Z","shell.execute_reply.started":"2026-02-27T03:30:39.346675Z","shell.execute_reply":"2026-02-27T03:30:39.362838Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Mutual Information (MI) Scores** is a non-linear approach used often in feature selection. It measures how much information the presence/absence of a feature contributes to making the correct prediction on the target.","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_selection import mutual_info_classif\n\n# We need to temporarily encode strings to numbers for MI\ntemp_df = df[['Pclass', 'Sex', 'Embarked', 'Survived']].copy()\ntemp_df['Sex'] = temp_df['Sex'].map({'male': 0, 'female': 1})\ntemp_df['Embarked'] = temp_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).fillna(-1)\n\nX = temp_df.drop('Survived', axis=1)\ny = temp_df['Survived']\n\nmi_scores = mutual_info_classif(X, y, discrete_features=True)\nmi_results = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\nprint(mi_results.sort_values(ascending=False))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.365196Z","iopub.execute_input":"2026-02-27T03:30:39.365647Z","iopub.status.idle":"2026-02-27T03:30:39.422571Z","shell.execute_reply.started":"2026-02-27T03:30:39.365609Z","shell.execute_reply":"2026-02-27T03:30:39.421739Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Sometimes a raw table is hard to read. Normalizing by index (row) shows you the likelihood of survival per category.","metadata":{}},{"cell_type":"code","source":"# What percentage of each Class survived?\npd.crosstab(df['Pclass'], df['Survived'], normalize='index')\n\n# Does Sex affect the Survival Rate of different Embarked ports?\npd.crosstab(index=[df['Sex'], df['Embarked']], columns=df['Survived'], normalize='index')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.427168Z","iopub.execute_input":"2026-02-27T03:30:39.427549Z","iopub.status.idle":"2026-02-27T03:30:39.453078Z","shell.execute_reply.started":"2026-02-27T03:30:39.427521Z","shell.execute_reply":"2026-02-27T03:30:39.452162Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3><b>Hands-on Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"Creating copy of the dataset before proceeding","metadata":{}},{"cell_type":"code","source":"df_fe = df.copy()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.454016Z","iopub.execute_input":"2026-02-27T03:30:39.454363Z","iopub.status.idle":"2026-02-27T03:30:39.460485Z","shell.execute_reply.started":"2026-02-27T03:30:39.454326Z","shell.execute_reply":"2026-02-27T03:30:39.459547Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Quickly see the data\ndf_fe.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.461685Z","iopub.execute_input":"2026-02-27T03:30:39.462128Z","iopub.status.idle":"2026-02-27T03:30:39.488818Z","shell.execute_reply.started":"2026-02-27T03:30:39.462093Z","shell.execute_reply":"2026-02-27T03:30:39.487673Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Group rare titles into \"Rare\" for stability\nrare_titles = df_fe[\"Title\"].value_counts()\nrare_titles = rare_titles[rare_titles < 10].index\ndf_fe[\"Title\"] = df_fe[\"Title\"].replace(rare_titles, \"Rare\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.490349Z","iopub.execute_input":"2026-02-27T03:30:39.490834Z","iopub.status.idle":"2026-02-27T03:30:39.504677Z","shell.execute_reply.started":"2026-02-27T03:30:39.490798Z","shell.execute_reply":"2026-02-27T03:30:39.503623Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_fe[\"IsAlone\"] = (df_fe[\"FamilySize\"] == 1).astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.505872Z","iopub.execute_input":"2026-02-27T03:30:39.506757Z","iopub.status.idle":"2026-02-27T03:30:39.520532Z","shell.execute_reply.started":"2026-02-27T03:30:39.506729Z","shell.execute_reply":"2026-02-27T03:30:39.519436Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Deck from Cabin (first letter), missing -> \"Unknown\"\ndf_fe[\"Deck\"] = df_fe[\"Cabin\"].astype(str).str[0]\ndf_fe[\"Deck\"] = df_fe[\"Deck\"].replace(\"n\", \"Unknown\")  # 'nan' -> 'n' after str conversion\ndf_fe[\"Deck\"] = df_fe[\"Deck\"].replace(\"N\", \"Unknown\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.521748Z","iopub.execute_input":"2026-02-27T03:30:39.522176Z","iopub.status.idle":"2026-02-27T03:30:39.539677Z","shell.execute_reply.started":"2026-02-27T03:30:39.522151Z","shell.execute_reply":"2026-02-27T03:30:39.538458Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Ticket group size (people sharing ticket sometimes correlate)\nticket_counts = df_fe[\"Ticket\"].value_counts()\ndf_fe[\"TicketGroupSize\"] = df_fe[\"Ticket\"].map(ticket_counts)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.540984Z","iopub.execute_input":"2026-02-27T03:30:39.541403Z","iopub.status.idle":"2026-02-27T03:30:39.55692Z","shell.execute_reply.started":"2026-02-27T03:30:39.541362Z","shell.execute_reply":"2026-02-27T03:30:39.555877Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Fare per person (avoid divide-by-zero; FamilySize >= 1 always here)\ndf_fe[\"FarePerPerson\"] = df_fe[\"Fare\"] / df_fe[\"FamilySize\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.557951Z","iopub.execute_input":"2026-02-27T03:30:39.558243Z","iopub.status.idle":"2026-02-27T03:30:39.57404Z","shell.execute_reply.started":"2026-02-27T03:30:39.558219Z","shell.execute_reply":"2026-02-27T03:30:39.57297Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop columns we won't use directly (IDs, high-cardinality, leakage-ish)\n# Keep 'Name' dropped after extracting Title\ndrop_cols = [\"PassengerId\", \"Name\", \"Cabin\", \"Ticket\"]\ndf_fe = df_fe.drop(columns=drop_cols)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.575347Z","iopub.execute_input":"2026-02-27T03:30:39.576052Z","iopub.status.idle":"2026-02-27T03:30:39.592553Z","shell.execute_reply.started":"2026-02-27T03:30:39.575977Z","shell.execute_reply":"2026-02-27T03:30:39.591188Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's check what we created","metadata":{}},{"cell_type":"code","source":"df_fe.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.593922Z","iopub.execute_input":"2026-02-27T03:30:39.594283Z","iopub.status.idle":"2026-02-27T03:30:39.621132Z","shell.execute_reply.started":"2026-02-27T03:30:39.594245Z","shell.execute_reply":"2026-02-27T03:30:39.620288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3><b>Define Training Features (X) and Target Variable (y)","metadata":{}},{"cell_type":"code","source":"target_col = \"Survived\"\n\n# if we drop the target column from all the features, it becomes training features\nX = df_fe.drop(columns=[target_col])\n# Now, as we have already defined target_col from the dataset, let's set that up\ny = df_fe[target_col].astype(int)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.622344Z","iopub.execute_input":"2026-02-27T03:30:39.622704Z","iopub.status.idle":"2026-02-27T03:30:39.639466Z","shell.execute_reply.started":"2026-02-27T03:30:39.622651Z","shell.execute_reply":"2026-02-27T03:30:39.638441Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Identify column data types for pre-processing\nnumerical_features = X.select_dtypes(include=[np.number]).columns.tolist()\ncategorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.640561Z","iopub.execute_input":"2026-02-27T03:30:39.640989Z","iopub.status.idle":"2026-02-27T03:30:39.657485Z","shell.execute_reply.started":"2026-02-27T03:30:39.640924Z","shell.execute_reply":"2026-02-27T03:30:39.656685Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Numerical Features:\", numerical_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.658525Z","iopub.execute_input":"2026-02-27T03:30:39.658854Z","iopub.status.idle":"2026-02-27T03:30:39.674918Z","shell.execute_reply.started":"2026-02-27T03:30:39.658823Z","shell.execute_reply":"2026-02-27T03:30:39.673716Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Categorical Features:\", categorical_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.675991Z","iopub.execute_input":"2026-02-27T03:30:39.676314Z","iopub.status.idle":"2026-02-27T03:30:39.69083Z","shell.execute_reply.started":"2026-02-27T03:30:39.67629Z","shell.execute_reply":"2026-02-27T03:30:39.689921Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3><b>Train / Validation Split (Stratified for Classification","metadata":{}},{"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, \n                                                 random_state=RANDOM_STATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:39.692116Z","iopub.execute_input":"2026-02-27T03:30:39.692547Z","iopub.status.idle":"2026-02-27T03:30:39.710463Z","shell.execute_reply.started":"2026-02-27T03:30:39.692511Z","shell.execute_reply":"2026-02-27T03:30:39.709626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Train:\", X_train.shape, \"Val:\", X_val.shape)\nprint(\"Train target rate:\", y_train.mean(), \"Val target rate:\", y_val.mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:30:44.543855Z","iopub.execute_input":"2026-02-27T03:30:44.544479Z","iopub.status.idle":"2026-02-27T03:30:44.549757Z","shell.execute_reply.started":"2026-02-27T03:30:44.544449Z","shell.execute_reply":"2026-02-27T03:30:44.548996Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3><b>Building Data Preprocessing Pipeline</b></h3>\n<li> Numeric: Impute missing values + scaling the feature values\n<li> Categorical: Impute missing values + one hot encoding","metadata":{}},{"cell_type":"code","source":"# Numeric data transformer\nnumeric_transformer = Pipeline(steps = [\n    (\"imputer\", SimpleImputer(strategy=\"median\")), \n    (\"scaler\", StandardScaler())\n])\n\n# Categorical data transformer\ncategorical_transformer = Pipeline(steps=[\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")), \n    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\n# Now, applying categorical and numerical data transformer to the processing step\npreprocessor = ColumnTransformer(\n    transformers = [\n        (\"num\", numeric_transformer, numerical_features), \n        (\"cat\", categorical_transformer, categorical_features)\n    ]\n)\n\nprint(\"Data Preprocessing is Performed!âœ…\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T03:38:23.876038Z","iopub.execute_input":"2026-02-27T03:38:23.87702Z","iopub.status.idle":"2026-02-27T03:38:23.88438Z","shell.execute_reply.started":"2026-02-27T03:38:23.876984Z","shell.execute_reply":"2026-02-27T03:38:23.883228Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3><b>Defining the function to evaluate any categorical machine learning model</b></h3>\nThis step will help us to define the function that will evaluate any classification model's performance so that we can quickly training more models and evaluate them without any issues.","metadata":{}},{"cell_type":"code","source":"def evaluate_classifier(model, X_tr, y_tr, X_te, y_te, model_name = \"model\"):\n    \"\"\"\n    This function fits the pipeline model and prints classification metrics. \n    Also, returns a dictionary of metrics for comparison.\n    \"\"\"\n\n    # Fitting training data to the model\n    model.fit(X_tr, y_tr)\n\n    # Perform predictions on the test data\n    y_pred = model.predict(X_te)\n\n    # Models like SVC output probability being True or some models can output probabilities\n    y_proba = None\n    if hasattr(model, \"predict_proba\"):\n        y_proba = model.predict_proba(X_te)[:, 1]\n\n    # ------------------------------------\n    # Model evaluation metrices\n    # ------------------------------------\n    acc = accuracy_score(y_te, y_pred) # calculating accuracy from actual test labels against predicted test labels\n    prec = precision_score(y_te, y_pred, zero_division=0)\n    rec = recall_score(y_te, y_pred, zero_division=0)\n    f1 = f1_score(y_te, y_pred, zero_division=0)\n\n    # ROC AUC score calculation if probabilities exist\n    auc = roc_auc_score(y_te, y_proba) if y_proba is not None else np.nan\n\n    # printing out all the results as part of model evaluation techniques\n    print(f\"\\n========== {model_name} ===========\")\n    print(f\"Accuracy: {acc:.4f}\")\n    print(f\"Precision: {prec:.4f}\")\n    print(f\"Recall: {rec:.4f}\")\n    print(f\"F1-score : {f1:.4f}\")\n    print(f\"ROC AUC: {auc:.4f}\" if not np.isnan(auc) else \"ROC-AUC: (No Probabilities to calculate ROC AUC)\")\n\n    # generating confusion matrix to see the True Positive, True Negative, False Positive and False Negative\n    print(\"\\nConfusioin Matrix: \")\n    print(confusion_matrix(y_te, y_pred))\n\n    # Printing classification report for entire training evaluation report\n    print(\"\\nClassification Report: \")\n    print(classification_report(y_te, y_pred, zero_division=0))\n\n    metrics = {\"Model\": model_name, \"Accuracy\": acc, \"Precision\": prec, \"Recall\": rec, \"F1-Score\": f1, \"ROC-AUC\": auc}\n    return metrics\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:19:58.91481Z","iopub.execute_input":"2026-02-27T04:19:58.91587Z","iopub.status.idle":"2026-02-27T04:19:58.925401Z","shell.execute_reply.started":"2026-02-27T04:19:58.915829Z","shell.execute_reply":"2026-02-27T04:19:58.924303Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Training and Evaluating Few Baseline Models</b></h2>\nIt is now finally time train a few baseline models and evaluate and see how they are doing. Later steps, we will tune those models","metadata":{}},{"cell_type":"code","source":"# Beginning with very basic but powerful decision tree model\ndt_clf = Pipeline(steps=[\n    (\"preprocess\", preprocessor), \n    (\"model\", DecisionTreeClassifier(random_state=RANDOM_STATE))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:19:59.961173Z","iopub.execute_input":"2026-02-27T04:19:59.96201Z","iopub.status.idle":"2026-02-27T04:19:59.966292Z","shell.execute_reply.started":"2026-02-27T04:19:59.961981Z","shell.execute_reply":"2026-02-27T04:19:59.965245Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# let's jump now to the RandomForest\nrf_clf = Pipeline(steps=[\n    (\"preprocess\", preprocessor), \n    (\"model\", RandomForestClassifier(\n        random_state=RANDOM_STATE, \n        n_estimators=300\n    ))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:20:02.724743Z","iopub.execute_input":"2026-02-27T04:20:02.725647Z","iopub.status.idle":"2026-02-27T04:20:02.730484Z","shell.execute_reply.started":"2026-02-27T04:20:02.725612Z","shell.execute_reply":"2026-02-27T04:20:02.729573Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# K-Nearest Neighbors (KNN) -> This model needs scaling which is already done above in numeric pipeline\nknn_clf = Pipeline(steps=[\n    (\"preprocess\", preprocessor), \n    (\"model\", KNeighborsClassifier())\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:20:02.868482Z","iopub.execute_input":"2026-02-27T04:20:02.869446Z","iopub.status.idle":"2026-02-27T04:20:02.87358Z","shell.execute_reply.started":"2026-02-27T04:20:02.869413Z","shell.execute_reply":"2026-02-27T04:20:02.872802Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Support Vector Classifier (Support ROC-AUC, enabling probability=True)\nsvc_clf = Pipeline(steps=[\n    (\"preprocess\", preprocessor), \n    (\"model\", SVC(probability=True, random_state = RANDOM_STATE))\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:20:03.241839Z","iopub.execute_input":"2026-02-27T04:20:03.242125Z","iopub.status.idle":"2026-02-27T04:20:03.247299Z","shell.execute_reply.started":"2026-02-27T04:20:03.242102Z","shell.execute_reply":"2026-02-27T04:20:03.246172Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Initializing empty list to store the results of model performances\nresults = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:20:06.388625Z","iopub.execute_input":"2026-02-27T04:20:06.389334Z","iopub.status.idle":"2026-02-27T04:20:06.393452Z","shell.execute_reply.started":"2026-02-27T04:20:06.389302Z","shell.execute_reply":"2026-02-27T04:20:06.392689Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Appending all the results from different models to empty list \"results\" that we initialized above\nresults.append(evaluate_classifier(dt_clf, X_train, y_train, X_val, y_val, model_name=\"DecisionTree (Baseline)\"))\nresults.append(evaluate_classifier(rf_clf, X_train, y_train, X_val, y_val, model_name=\"RandomForest (Baseline)\"))\nresults.append(evaluate_classifier(knn_clf, X_train, y_train, X_val, y_val, model_name=\"KNN (Baseline)\"))\nresults.append(evaluate_classifier(svc_clf, X_train, y_train, X_val, y_val, model_name=\"SVC (Baseline\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:20:06.773196Z","iopub.execute_input":"2026-02-27T04:20:06.773726Z","iopub.status.idle":"2026-02-27T04:20:08.738994Z","shell.execute_reply.started":"2026-02-27T04:20:06.77369Z","shell.execute_reply":"2026-02-27T04:20:08.73832Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df = pd.DataFrame(results).sort_values(by=\"F1-Score\", ascending=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:20:15.377964Z","iopub.execute_input":"2026-02-27T04:20:15.379064Z","iopub.status.idle":"2026-02-27T04:20:15.384878Z","shell.execute_reply.started":"2026-02-27T04:20:15.379021Z","shell.execute_reply":"2026-02-27T04:20:15.383986Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"results_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:20:21.451242Z","iopub.execute_input":"2026-02-27T04:20:21.451551Z","iopub.status.idle":"2026-02-27T04:20:21.463412Z","shell.execute_reply.started":"2026-02-27T04:20:21.451527Z","shell.execute_reply":"2026-02-27T04:20:21.462443Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h2><b>Hyperparameter Tuning</b></h2>\nLooks like models did learn faily well, however, I think we can do even better from model's performance standpoint. \nSo we will perform hyperparameter tuning individually on each of the the models and see how they are performing. ","metadata":{}},{"cell_type":"code","source":"# Please check back for the next step on hands-on hyperparameter tuning. In a couple of days, I will make updates further with detailed\n# hyperparameter tuning on each of those models. \n\n# Until then, please follow and subscribe: Data speaks YouTube channel:","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T04:23:21.933788Z","iopub.execute_input":"2026-02-27T04:23:21.934248Z","iopub.status.idle":"2026-02-27T04:23:21.93838Z","shell.execute_reply.started":"2026-02-27T04:23:21.934221Z","shell.execute_reply":"2026-02-27T04:23:21.937408Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"https://www.youtube.com/@DataSpeaks4u","metadata":{}},{"cell_type":"markdown","source":"<h1><b>For submission only","metadata":{}},{"cell_type":"markdown","source":"Only for submission in Kaggle, not much helpful for learning!","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:17:39.041351Z","iopub.execute_input":"2026-02-27T05:17:39.041774Z","iopub.status.idle":"2026-02-27T05:17:45.440565Z","shell.execute_reply.started":"2026-02-27T05:17:39.041732Z","shell.execute_reply":"2026-02-27T05:17:45.439812Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1. LOAD DATA\n# 1. Load the data\ntrain = pd.read_csv('/kaggle/input/competitions/titanic/train.csv')\ntest = pd.read_csv('/kaggle/input/competitions/titanic/test.csv')\n\npassenger_ids = test['PassengerId']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:17:48.329888Z","iopub.execute_input":"2026-02-27T05:17:48.330236Z","iopub.status.idle":"2026-02-27T05:17:48.366142Z","shell.execute_reply.started":"2026-02-27T05:17:48.330205Z","shell.execute_reply":"2026-02-27T05:17:48.365089Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2. ADVANCED FEATURE ENGINEERING\ndef engineer_features(df):\n    # Extract Title and group rare ones\n    df['Title'] = df.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n    df['Title'] = df['Title'].replace(['Lady', 'Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n    df['Title'] = df['Title'].replace(['Mlle', 'Ms'], 'Miss')\n    df['Title'] = df['Title'].replace('Mme', 'Mrs')\n    \n    # Impute Age based on Title (more accurate than global median)\n    df['Age'] = df.groupby('Title')['Age'].transform(lambda x: x.fillna(x.median()))\n    \n    # Cabin Deck extraction (First letter of Cabin)\n    df['Deck'] = df['Cabin'].apply(lambda x: x[0] if pd.notnull(x) else 'U') # 'U' for Unknown\n    \n    # Family Size & Groups\n    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n    df['IsAlone'] = (df['FamilySize'] == 1).astype(int)\n    \n    # Fare Imputation & Binning\n    df['Fare'] = df['Fare'].fillna(df['Fare'].median())\n    df['FareBin'] = pd.qcut(df['Fare'], 4, labels=[0, 1, 2, 3]).astype(int)\n    \n    # Cleanup\n    df.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1, inplace=True)\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:17:58.504962Z","iopub.execute_input":"2026-02-27T05:17:58.505824Z","iopub.status.idle":"2026-02-27T05:17:58.514815Z","shell.execute_reply.started":"2026-02-27T05:17:58.505791Z","shell.execute_reply":"2026-02-27T05:17:58.513869Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = engineer_features(train)\ntest = engineer_features(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:18:08.613439Z","iopub.execute_input":"2026-02-27T05:18:08.613817Z","iopub.status.idle":"2026-02-27T05:18:08.660915Z","shell.execute_reply.started":"2026-02-27T05:18:08.61375Z","shell.execute_reply":"2026-02-27T05:18:08.659866Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3. ENCODING\n# Use Label Encoding for categorical features\ncategorical = ['Sex', 'Embarked', 'Title', 'Deck']\nfor col in categorical:\n    le = LabelEncoder()\n    # Fit on combined data to ensure all labels are captured\n    combined = pd.concat([train[col], test[col]], axis=0).astype(str)\n    le.fit(combined)\n    train[col] = le.transform(train[col].astype(str))\n    test[col] = le.transform(test[col].astype(str))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:18:17.530312Z","iopub.execute_input":"2026-02-27T05:18:17.530683Z","iopub.status.idle":"2026-02-27T05:18:17.544521Z","shell.execute_reply.started":"2026-02-27T05:18:17.530652Z","shell.execute_reply":"2026-02-27T05:18:17.543233Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X = train.drop('Survived', axis=1)\ny = train['Survived']\n\nprint(\"Code executed so far!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:18:25.532315Z","iopub.execute_input":"2026-02-27T05:18:25.532676Z","iopub.status.idle":"2026-02-27T05:18:25.539926Z","shell.execute_reply.started":"2026-02-27T05:18:25.532644Z","shell.execute_reply":"2026-02-27T05:18:25.538895Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4. THE ENSEMBLE MODEL\n# Define three strong, diverse learners\nclf1 = RandomForestClassifier(n_estimators=500, max_depth=6, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:18:36.806803Z","iopub.execute_input":"2026-02-27T05:18:36.807149Z","iopub.status.idle":"2026-02-27T05:18:36.811698Z","shell.execute_reply.started":"2026-02-27T05:18:36.807119Z","shell.execute_reply":"2026-02-27T05:18:36.810838Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf2 = xgb.XGBClassifier(n_estimators=500, max_depth=4, learning_rate=0.01, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:18:44.268415Z","iopub.execute_input":"2026-02-27T05:18:44.268773Z","iopub.status.idle":"2026-02-27T05:18:44.273536Z","shell.execute_reply.started":"2026-02-27T05:18:44.268745Z","shell.execute_reply":"2026-02-27T05:18:44.272622Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"clf3 = lgb.LGBMClassifier(n_estimators=500, max_depth=4, learning_rate=0.01, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:18:51.10064Z","iopub.execute_input":"2026-02-27T05:18:51.100993Z","iopub.status.idle":"2026-02-27T05:18:51.105718Z","shell.execute_reply.started":"2026-02-27T05:18:51.100965Z","shell.execute_reply":"2026-02-27T05:18:51.10474Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Combine them using a Soft Voting Classifier\n# \"Soft\" uses predicted probabilities rather than just \"Hard\" majority vote\nvoting_clf = VotingClassifier(\n    estimators=[('rf', clf1), ('xgb', clf2), ('lgbm', clf3)],\n    voting='soft'\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:19:00.588536Z","iopub.execute_input":"2026-02-27T05:19:00.588876Z","iopub.status.idle":"2026-02-27T05:19:00.593698Z","shell.execute_reply.started":"2026-02-27T05:19:00.588846Z","shell.execute_reply":"2026-02-27T05:19:00.592581Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5. TRAIN AND SUBMIT\nvoting_clf.fit(X, y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:19:12.316624Z","iopub.execute_input":"2026-02-27T05:19:12.316936Z","iopub.status.idle":"2026-02-27T05:19:13.746741Z","shell.execute_reply.started":"2026-02-27T05:19:12.31691Z","shell.execute_reply":"2026-02-27T05:19:13.74603Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = voting_clf.predict(test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:19:45.406417Z","iopub.execute_input":"2026-02-27T05:19:45.40678Z","iopub.status.idle":"2026-02-27T05:19:45.485993Z","shell.execute_reply.started":"2026-02-27T05:19:45.406749Z","shell.execute_reply":"2026-02-27T05:19:45.485086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': passenger_ids, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint(\"Advanced submission file saved!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-27T05:20:12.741073Z","iopub.execute_input":"2026-02-27T05:20:12.74142Z","iopub.status.idle":"2026-02-27T05:20:12.754359Z","shell.execute_reply.started":"2026-02-27T05:20:12.741393Z","shell.execute_reply":"2026-02-27T05:20:12.753387Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}